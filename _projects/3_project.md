---
layout: page
title: Adversarial Robustness Testing of CNNs with FGSM
description: Implemented a Fast Gradient Sign Method (FGSM) adversarial attack in PyTorch by training a convolutional neural network (CNN) and generating imperceptibly perturbed inputs that caused controlled misclassification, strengthening understanding of ML model vulnerabilities and adversarial-robust defense.
img:
redirect: https://github.com/miravuong/aml-cnn
importance: 2
techstack: Python (Pytorch), Google Colab (visualizations)
---
